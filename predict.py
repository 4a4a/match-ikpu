import pandas as pd
import numpy as np
import hashlib
from tqdm import tqdm
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
from utils import (
    preprocess_text, load_product_data, load_ikpu_data,
    build_ikpu_text, load_embeddings, validate_cache
)

# === –ü–∞—Ä–∞–º–µ—Ç—Ä—ã ===
SIMILARITY_THRESHOLD = 0.5
PRODUCTS_PATH = "data/products.xlsx"
IKPU_PATH = "data/ikpu_codes.xlsx"
FEEDBACK_PATH = "data/feedback.xlsx"
CATALOG_EMBED_FILE = "data/ikpu_catalog_embeddings.npz"
CATALOG_CHECKSUM_FILE = "data/ikpu_catalog_checksums.csv"
FEEDBACK_EMBED_FILE = "data/ikpu_feedback_embeddings.npz"
FEEDBACK_CHECKSUM_FILE = "data/ikpu_feedback_checksums.csv"
BATCH_SIZE = 64

# === –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ ===
def md5_hash(text):
    return hashlib.md5(text.encode("utf-8")).hexdigest()

def build_checksum(df):
    return (df['–ò–ö–ü–£'].astype(str) + '|' + df['text'].apply(md5_hash)).tolist()

def save_embeddings(file, texts, vectors, codes, names, checksums):
    np.savez_compressed(file, vectors=vectors, codes=codes, names=names, texts=texts)
    pd.DataFrame({"–ò–ö–ü–£": codes, "text": texts, "checksum": checksums})\
      .to_csv(file.replace(".npz", "_checksums.csv"), index=False)

def encode_batch(model_instance, texts):
    return model_instance.encode(texts, batch_size=BATCH_SIZE, convert_to_tensor=False, show_progress_bar=True)

def find_best_match(query_text, embeddings, ikpu_df, model):
    query_vec = model.encode(query_text, convert_to_tensor=False)
    sims = cosine_similarity([query_vec], embeddings)[0]
    idx = np.argmax(sims)
    return ikpu_df.iloc[idx], sims[idx]

# === –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö ===
products = load_product_data(PRODUCTS_PATH)
ikpu = load_ikpu_data(IKPU_PATH)
products.columns = products.columns.str.strip()
ikpu.columns = ikpu.columns.str.strip()

# === –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Ç–µ–∫—Å—Ç–æ–≤ ===
products["query"] = (
    products["–ù–∞–∑–≤–∞–Ω–∏–µ"].fillna("") + " " +
    products["–ö–∞—Ç–µ–≥–æ—Ä–∏—è"].fillna("") + " " +
    products["brand"].fillna("")
).apply(preprocess_text)

ikpu["brand"] = ikpu.get("brand", ikpu.iloc[:, 4])
ikpu["–ì—Ä—É–ø–ø–∞"] = ikpu["–ö–ª–∞—Å—Å"]
ikpu["text"] = build_ikpu_text(ikpu)
catalog = ikpu.copy()
catalog_checksums = build_checksum(catalog)

# === Feedback ===
try:
    feedback = pd.read_excel(FEEDBACK_PATH)
    feedback.columns = feedback.columns.str.strip()
    ikpu_dict = ikpu.set_index("–ò–ö–ü–£")["–ù–∞–∑–≤–∞–Ω–∏–µ –ò–ö–ü–£"].astype(str).to_dict()

    feedback["–ù–∞–∑–≤–∞–Ω–∏–µ –ò–ö–ü–£"] = feedback["–ò–ö–ü–£"].map(ikpu_dict)
    feedback["text"] = feedback["–ù–∞–∑–≤–∞–Ω–∏–µ –ò–ö–ü–£"].fillna("").apply(preprocess_text)
    feedback["–ì—Ä—É–ø–ø–∞"] = feedback["–ò–ö–ü–£"].map(ikpu.set_index("–ò–ö–ü–£")["–ö–ª–∞—Å—Å"])
    feedback_checksums = build_checksum(feedback)
    print(f"üìå –ó–∞–≥—Ä—É–∂–µ–Ω–æ –∏–∑ feedback: {len(feedback)} –∑–∞–ø–∏—Å–µ–π")
except FileNotFoundError:
    feedback = pd.DataFrame(columns=["–ò–ö–ü–£", "text", "–ì—Ä—É–ø–ø–∞"])
    feedback_checksums = []
    print("‚ÑπÔ∏è feedback.xlsx –Ω–µ –Ω–∞–π–¥–µ–Ω ‚Äî –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –¥–æ–æ–±—É—á–µ–Ω–∏–µ.")

# === –ú–æ–¥–µ–ª—å ===
print("üîÑ –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å BERT...")
model = SentenceTransformer("paraphrase-multilingual-MiniLM-L12-v2")

# === –í–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è –∫–∞—Ç–∞–ª–æ–≥–∞ ===
if validate_cache(CATALOG_CHECKSUM_FILE, catalog_checksums):
    print("‚úÖ –ö–µ—à –∫–∞—Ç–∞–ª–æ–≥–∞ –≤–∞–ª–∏–¥–µ–Ω ‚Äî –∑–∞–≥—Ä—É–∂–∞–µ–º")
    _, catalog_vecs_np, catalog_codes, catalog_names = load_embeddings(CATALOG_EMBED_FILE)
    catalog_vecs = catalog_vecs_np.tolist()
else:
    print("‚ö†Ô∏è –ö–µ—à –∫–∞—Ç–∞–ª–æ–≥–∞ —É—Å—Ç–∞—Ä–µ–ª –∏–ª–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç ‚Äî –ø–µ—Ä–µ—Å—á–∏—Ç—ã–≤–∞–µ–º")
    catalog_vecs = encode_batch(model, catalog["text"].tolist())
    save_embeddings(
        CATALOG_EMBED_FILE,
        catalog["text"].tolist(),
        np.array(catalog_vecs),
        catalog["–ò–ö–ü–£"].astype(str).tolist(),
        catalog["–ù–∞–∑–≤–∞–Ω–∏–µ –ò–ö–ü–£"].tolist(),
        catalog_checksums
    )

# === –í–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è feedback ===
if not feedback.empty:
    if validate_cache(FEEDBACK_CHECKSUM_FILE, feedback_checksums):
        print("‚úÖ –ö–µ—à feedback –≤–∞–ª–∏–¥–µ–Ω ‚Äî –∑–∞–≥—Ä—É–∂–∞–µ–º")
        _, feedback_vecs_np, feedback_codes, feedback_names = load_embeddings(FEEDBACK_EMBED_FILE)
        feedback_vecs = feedback_vecs_np.tolist()
    else:
        print("‚ö†Ô∏è –ö–µ—à feedback —É—Å—Ç–∞—Ä–µ–ª –∏–ª–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç ‚Äî –ø–µ—Ä–µ—Å—á–∏—Ç—ã–≤–∞–µ–º")
        feedback_vecs = encode_batch(model, feedback["text"].tolist())
        save_embeddings(
            FEEDBACK_EMBED_FILE,
            feedback["text"].tolist(),
            np.array(feedback_vecs),
            feedback["–ò–ö–ü–£"].astype(str).tolist(),
            feedback["–ù–∞–∑–≤–∞–Ω–∏–µ –ò–ö–ü–£"].tolist(),
            feedback_checksums
        )
else:
    feedback_vecs = []
    feedback = pd.DataFrame()

# === –û–±—ä–µ–¥–∏–Ω—ë–Ω–Ω—ã–π –∫–∞—Ç–∞–ª–æ–≥ ===
all_embeddings = np.vstack([catalog_vecs, feedback_vecs])
all_ikpu = pd.concat([catalog, feedback], ignore_index=True)

# === –ü–æ–∏—Å–∫ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π ===
results = []
print("üöÄ –ü–æ–∏—Å–∫ –±–ª–∏–∂–∞–π—à–∏—Ö —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π...")

for _, row in tqdm(products.iterrows(), total=len(products), desc="üîç –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–æ–≤–∞—Ä–æ–≤"):
    best_row, best_score = find_best_match(row["query"], all_embeddings, all_ikpu, model)
    results.append({
        "ID": row["ID"],
        "–ù–∞–∑–≤–∞–Ω–∏–µ": row["–ù–∞–∑–≤–∞–Ω–∏–µ"],
        "–ö–∞—Ç–µ–≥–æ—Ä–∏—è": row["–ö–∞—Ç–µ–≥–æ—Ä–∏—è"],
        "brand": row["brand"],
        "–ò–ö–ü–£": str(best_row["–ò–ö–ü–£"]).zfill(17),
        "–ù–∞–∑–≤–∞–Ω–∏–µ –ò–ö–ü–£": best_row["–ù–∞–∑–≤–∞–Ω–∏–µ –ò–ö–ü–£"],
        "–ü–æ—Ö–æ–∂–µ—Å—Ç—å": round(float(best_score), 4),
        "–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π": "–ù–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å" if best_score < SIMILARITY_THRESHOLD else "OK"
    })

# === –≠–∫—Å–ø–æ—Ä—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ ===
result_df = pd.DataFrame(results)
result_df.to_excel("data/predicted_ikpu.xlsx", index=False)
print("‚úÖ –ì–æ—Ç–æ–≤–æ! –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ data/predicted_ikpu.xlsx")
